# AttackSeqBench
AttackSeqBench is a novel Question Answering (QA) benchmark designed to systematically evaluate the capabilities of LLMs in understanding attack sequences found in Cyber Threat Intelligence (CTI) reports. We carefully an automated dataset construction pipeline, enabling us to create a scalable and well-formulated QA dataset based on real-world CTI reports. AttackSeqBench consists of three tasks, each task focuses on the varying granularity of adversarial behavior as described using Tactics, Techniques and Procedures (TTPs). We conduct extensive experiments and analysis with
a diverse set of fast-thinking and slow-thinking LLMs, while highlighting the strengths and limitations of LLMs in understanding CTI reports and threat behavior reasoning. The overarching goal of this work is to provide a benchmark that advances LLM-driven cybersecurity operations. CTI report understanding and fosters its application in real-worldOur dataset can be found in the `/dataset` directory.

## Dataset Construction Pipeline
The code for the dataset construction pipeline is divided into two directories: 
- `/question_generation` generates and construct each benchmark task using LLMs to form the initial QA dataset.
- `/question_refinement` filters and refines the QA pairs in the initial dataset.

### Quick Start
1. Modify the `.env.example` file with your HuggingFace and OpenAI API tokens and rename it to `.env`.
2. Install the Python dependencies: `pip install -r requirements.txt`
3. To generate the questions, run `/question_generation/run_question_generation_pipeline.py`. Note that this generates all tasks except for AttackSeq-Procedure-No, as the subtask is generated only after the AttackSeq-Procedure-Yes has been refined.
4. To run the self-refinement pipeline, run `/question_refinement/run_refinement_pipeline.py`.
5. Afterwards, the questions for AttackSeq-Procedure-No can be generated by running `/question_generation/generate_no_procedure_questions.py`, and `/question_generation/construct_AttackSeq_Procedure_No.py` afterwards.
